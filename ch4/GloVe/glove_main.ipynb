{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Peter\\Anaconda36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from build_dataset_bz2 import word2VecDataset\n",
    "from global_vector_model import gloVeModel\n",
    "from tensorflow_graph_in_jupyter import show_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified ../../wikipedia2text-extracted.txt.bz2\n",
      "file_size 18377035\n",
      "Reading data...\n",
      "text_digt: ['propaganda', 'is', 'a', 'concerted', 'set', 'of', 'messages', 'aimed']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7fc38ec0c57a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdata_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mglv_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgloVeModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m#batch, labels, weights = glv_mod._generate_batch_GloVe(\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#          text_digt, batch_size=8, window_size=4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\A SyncWebStorage\\Machine Learning Programming\\NLP Tensorflow\\NLPwithTF_Code\\ch4\\GloVe\\global_vector_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_size, window_size, num_steps, embedding_size, valid_size, valid_window, num_sampled, vocab_size)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_window\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_sampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_sampled\u001b[0m \u001b[1;31m# Number of negative examples to sample.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_index' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    reset_graph()\n",
    "    url = 'http://www.evanjones.ca/software/'\n",
    "    \n",
    "    w2v_dataset= word2VecDataset()    \n",
    "    words = w2v_dataset.read_data('../../wikipedia2text-extracted.txt.bz2', 18377035)\n",
    "                \n",
    "      \n",
    "    text_digt,count,dictionary,reverse_dictionary =\\\n",
    "            w2v_dataset.build_dataset(words)\n",
    "    \n",
    "    del words\n",
    "    print('text_digt:', [reverse_dictionary[di] for di in text_digt[:8]])\n",
    "    # global data_index\n",
    "    data_index = 0\n",
    "    \n",
    "    glv_mod = gloVeModel(num_steps = 100001)           \n",
    "    #batch, labels, weights = glv_mod._generate_batch_GloVe(\\\n",
    "    #          text_digt, batch_size=8, window_size=4)\n",
    "    #print('\\nwith window_size = %d:' %window_size)\n",
    "    #print('    batch:', [reverse_dictionary[bi] for bi in batch])\n",
    "    #print('    labels:', [reverse_dictionary[li] for li\\\n",
    "    #                          in labels.reshape(8)])\n",
    "    #print('    weights:', [w for w in weights])\n",
    "        \n",
    "   \n",
    "    glv_mod.fit(text_digt = text_digt,\\\n",
    "                reverse_dictionary=reverse_dictionary,\\\n",
    "                batch_size =128, window_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
