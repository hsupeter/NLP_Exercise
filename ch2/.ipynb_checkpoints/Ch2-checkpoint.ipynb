{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Peter\\Anaconda36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48699152 0.47580582 0.5317505  0.5096687  0.5307768 ]]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "session = tf.InteractiveSession(graph = graph)\n",
    "X = tf.placeholder(shape = [1, 10], dtype = tf.float32, name='X')\n",
    "W = tf.Variable(tf.random_uniform(shape=[10, 5], minval = -0.1,\n",
    "    maxval = 0.1, dtype = tf.float32), name = 'W')\n",
    "b = tf.Variable(tf.zeros(shape=[5], dtype = tf.float32), name = 'b')\n",
    "h = tf.nn.sigmoid(tf.matmul(X, W) + b)\n",
    "tf.global_variables_initializer().run()\n",
    "h_eval = session.run(h, feed_dict={X: np.random.rand(1, 10)})\n",
    "print(h_eval)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21380568 0.08031817 0.8245768  0.5802096  0.42462397 0.05889028\n",
      "  0.25745592 0.12465554 0.7066572  0.9917598 ]]\n",
      "[[0.4735428  0.49723572 0.48502335 0.5140406  0.47169268]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(shape = [1, 10], dtype = tf.float32, name='X')\n",
    "w = tf.Variable(tf.random_uniform(shape=[10, 5], minval = -0.1,\n",
    "    maxval = 0.1, dtype = tf.float32), name = 'w')\n",
    "b = tf.Variable(tf.zeros(shape=[5], dtype = tf.float32), name = 'b')\n",
    "h = tf.nn.sigmoid(tf.matmul(X, w) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    X_eval, h_eval = sess.run([X,h], feed_dict={X: np.random.rand(1, 10)})\n",
    "    print(X_eval)\n",
    "    print(h_eval)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test1.txt found.\n",
      "File test2.txt found.\n",
      "File test3.txt found.\n",
      "========== Step 0 ===========\n",
      " Evaluated data (X)\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      " Evaluated data (h)\n",
      "[[0.4978232  0.49680147 0.49399936 0.50070715 0.5026781 ]\n",
      " [0.4978232  0.49680147 0.49399936 0.50070715 0.5026781 ]\n",
      " [0.4978232  0.49680147 0.49399936 0.50070715 0.5026781 ]]\n",
      "\n",
      "========== Step 1 ===========\n",
      " Evaluated data (X)\n",
      "[[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      " [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      " Evaluated data (h)\n",
      "[[0.48389488 0.48147577 0.46060568 0.51262486 0.52592736]\n",
      " [0.48389488 0.48147577 0.46060568 0.51262486 0.52592736]\n",
      " [0.4978232  0.49680147 0.49399936 0.50070715 0.5026781 ]]\n",
      "\n",
      "========== Step 2 ===========\n",
      " Evaluated data (X)\n",
      "[[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      " [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      " [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]]\n",
      " Evaluated data (h)\n",
      "[[0.48389488 0.48147577 0.46060568 0.51262486 0.52592736]\n",
      " [0.48389488 0.48147577 0.46060568 0.51262486 0.52592736]\n",
      " [0.48389488 0.48147577 0.46060568 0.51262486 0.52592736]]\n",
      "\n",
      "========== Step 3 ===========\n",
      " Evaluated data (X)\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n",
      " [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]]\n",
      " Evaluated data (h)\n",
      "[[0.4978232  0.49680147 0.49399936 0.50070715 0.5026781 ]\n",
      " [0.49216715 0.48335397 0.47349104 0.49515113 0.5035086 ]\n",
      " [0.49216715 0.48335397 0.47349104 0.49515113 0.5035086 ]]\n",
      "\n",
      "========== Step 4 ===========\n",
      " Evaluated data (X)\n",
      "[[1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n",
      " [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n",
      " [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]]\n",
      " Evaluated data (h)\n",
      "[[0.49216715 0.48335397 0.47349104 0.49515113 0.5035086 ]\n",
      " [0.49216715 0.48335397 0.47349104 0.49515113 0.5035086 ]\n",
      " [0.48389488 0.48147577 0.46060568 0.51262486 0.52592736]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the graph and session\n",
    "graph = tf.Graph() # Create a graph\n",
    "session = tf.InteractiveSession(graph = graph) # Create a session\n",
    "# The filename queue\n",
    "filenames = ['test%d.txt'%i for i in range(1, 4)]\n",
    "filename_queue = tf.train.string_input_producer(filenames, capacity = 3,\n",
    "                 shuffle = True, name='string_input_producer')\n",
    "\n",
    "# check if all files exist\n",
    "for f in filenames:\n",
    "    if not tf.gfile.Exists(f):\n",
    "        raise ValueError('Failed to find file:' + f)\n",
    "    else:\n",
    "        print('File %s found.'%f)\n",
    "\n",
    "# Reader which takes a foilename queue and\n",
    "# read() which outputs data one by one\n",
    "reader = tf.TextLineReader()\n",
    "\n",
    "# Ready the data of the file and outputs as key, valu pairs\n",
    "# We're discarding the key\n",
    "key, value = reader.read(filename_queue, name = 'text_read_op')\n",
    "\n",
    "# If any problems encountered with reading file, the value returned:\n",
    "record_defaults = [[-1.0], [-1.0], [-1.0], [-1.0], [-1.0],\n",
    "                   [-1.0], [-1.0], [-1.0], [-1.0], [-1.0],]\n",
    "\n",
    "# Decoding the read value to columns\n",
    "col1,col2,col3,col4,col5,col6,col7,col8,col9,col10 = tf.decode_csv(value,\n",
    "                                      record_defaults = record_defaults)\n",
    "features = tf.stack([col1,col2,col3,col4,col5,col6,col7,col8,col9,col10])\n",
    "\n",
    "# Output x is randomly assigned a batch of data of batch_size\n",
    "# Where the data id read from the txt files\n",
    "X = tf.train.shuffle_batch([features], batch_size = 3,\n",
    "                           capacity = 5, name = 'data_batch',\n",
    "                           min_after_dequeue=1, num_threads=1)\n",
    "# QueueRunner retrieve data from queues and we need to explicity start them\n",
    "# Coordinator coordinates multiple QueueRunner\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord = coord, sess = session)\n",
    "\n",
    "# Building the graph by defining the variables and calculations\n",
    "w = tf.Variable(tf.random_uniform(shape=[10, 5], minval=-0.1, maxval= 0.1,\n",
    "                                  dtype=tf.float32), name = 'w') # Variable\n",
    "b = tf.Variable(tf.zeros(shape=[5], dtype=tf.float32), name ='b') # Variable\n",
    "h = tf.nn.sigmoid(tf.matmul(X, w) + b) # Operation to be performed\n",
    "\n",
    "# Executing operations and evaluating nodes in the graph\n",
    "tf.global_variables_initializer().run() # Initialize the variables\n",
    "\n",
    "# Calculate h with x and print the results foe 5 steps\n",
    "for step in range(5):\n",
    "    X_eval, h_eval = session.run([X,h])\n",
    "    print('========== Step %d ===========' %step)\n",
    "    print(' Evaluated data (X)')\n",
    "    print(X_eval)\n",
    "    print(' Evaluated data (h)')\n",
    "    print(h_eval)\n",
    "    print('')\n",
    "\n",
    "# We also need to explicitly stop the coordinator\n",
    "# otherwise the process will hang indefinitely\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test1.txt found.\n",
      "File test2.txt found.\n",
      "File test3.txt found.\n",
      "========== Step 0 ===========\n",
      " Evaluated data (X)\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      " Evaluated data (h)\n",
      "[[0.49393374 0.50692004 0.49999756 0.4956141  0.49374092]\n",
      " [0.49393374 0.50692004 0.49999756 0.4956141  0.49374092]\n",
      " [0.49393374 0.50692004 0.49999756 0.4956141  0.49374092]]\n",
      "\n",
      "========== Step 1 ===========\n",
      " Evaluated data (X)\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      " [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]]\n",
      " Evaluated data (h)\n",
      "[[0.49393374 0.50692004 0.49999756 0.4956141  0.49374092]\n",
      " [0.49393374 0.50692004 0.49999756 0.4956141  0.49374092]\n",
      " [0.45790985 0.5313141  0.49761048 0.4851557  0.48485464]]\n",
      "\n",
      "========== Step 2 ===========\n",
      " Evaluated data (X)\n",
      "[[1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n",
      " [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n",
      " [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]]\n",
      " Evaluated data (h)\n",
      "[[0.45790985 0.5313141  0.49761048 0.4851557  0.48485464]\n",
      " [0.45790985 0.5313141  0.49761048 0.4851557  0.48485464]\n",
      " [0.45790985 0.5313141  0.49761048 0.4851557  0.48485464]]\n",
      "\n",
      "========== Step 3 ===========\n",
      " Evaluated data (X)\n",
      "[[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      " [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      " [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]]\n",
      " Evaluated data (h)\n",
      "[[0.4754776  0.54465044 0.5023628  0.46665224 0.446502  ]\n",
      " [0.4754776  0.54465044 0.5023628  0.46665224 0.446502  ]\n",
      " [0.45790985 0.5313141  0.49761048 0.4851557  0.48485464]]\n",
      "\n",
      "========== Step 4 ===========\n",
      " Evaluated data (X)\n",
      "[[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      " [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      " Evaluated data (h)\n",
      "[[0.4754776  0.54465044 0.5023628  0.46665224 0.446502  ]\n",
      " [0.4754776  0.54465044 0.5023628  0.46665224 0.446502  ]\n",
      " [0.49393374 0.50692004 0.49999756 0.4956141  0.49374092]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' 建立檔名佇列\n",
    "有了所有的檔案名稱之後，接著把檔名總表傳入tf.train.string_input_producer函數，\n",
    "建立檔案名稱佇列（queue）\n",
    "'''\n",
    "filenames = ['test%d.txt'%i for i in range(1, 4)]\n",
    "filename_queue = tf.train.string_input_producer(filenames, capacity = 3,\n",
    "                 shuffle = True, name='string_input_producer')\n",
    "\n",
    "# check if all files exist\n",
    "for f in filenames:\n",
    "    if not tf.gfile.Exists(f):\n",
    "        raise ValueError('Failed to find file:' + f)\n",
    "    else:\n",
    "        print('File %s found.'%f)\n",
    "\n",
    "'''讀取檔案\n",
    "根據自己的檔案格式，選擇一個適合的檔案讀取器，這裡我們要讀取的檔案是 CSV 檔，\n",
    "這種檔案的資料格式是一行一筆資料，所以適合使用 tf.TextLineReader 這個讀取器。\n",
    "將建立好的檔名佇列傳入讀取器：'''\n",
    "# 選擇讀取器\n",
    "reader = tf.TextLineReader()\n",
    "\n",
    "# 讀取檔案\n",
    "# key值辨識檔案與資料（可用於除錯），value實際的資料 \n",
    "key, value = reader.read(filename_queue, name = 'text_read_op')\n",
    "\n",
    "'''將檔案中的資料讀取進來之後，接著要進行資料解析與前處理的動作，\n",
    "   將文字的資料轉換為tensor，這樣才能放入 TensorFlow 中使用。\n",
    "   CSV 的資料我們可以使用 tf.decode_csv 這個解析器，它可以把 CSV 的文字資料\n",
    "   轉為一連串的 tensors：'''\n",
    "\n",
    "# 設定每個欄位預設的值以及資料類型\n",
    "record_defaults = [[-1.0], [-1.0], [-1.0], [-1.0], [-1.0],\n",
    "                   [-1.0], [-1.0], [-1.0], [-1.0], [-1.0],]\n",
    "\n",
    "# 解析 CSV 資料  Decoding the read value to columns\n",
    "col1,col2,col3,col4,col5,col6,col7,col8,col9,col10 = tf.decode_csv(value,\n",
    "                                      record_defaults = record_defaults)\n",
    "# 把 CSV 資料的前四欄打包成一個 tensor\n",
    "features = tf.stack([col1,col2,col3,col4,col5,col6,col7,col8,col9,col10])\n",
    "\n",
    "# tf.train.shuffle_batch()部分參數\n",
    "# tensor_list: The list of tensors to enqueue.入隊的張量列表\n",
    "# batch_size: The new batch size pulled from the queue.進行一次批次的tensor數\n",
    "# capacity: An integer. The maximum number of elements in the queue.推薦值:\n",
    "#  capacity=(min_after_dequeue+(num_threads+a small safety margin∗batchsize)\n",
    "# min_after_dequeue: Minimum number elements in the queue after a dequeue\n",
    "#                    (出列), used to ensure a level of mixing of elements.\n",
    "# num_threads: The number of threads enqueuing tensor_list.\n",
    "# 參看 https://blog.csdn.net/u013555719/article/details/77679964\n",
    "X = tf.train.shuffle_batch([features], batch_size = 3,\n",
    "                           capacity = 5, name = 'data_batch',\n",
    "                           min_after_dequeue=1, num_threads=1)\n",
    "\n",
    "# Building the graph by defining the variables and calculations\n",
    "w = tf.Variable(tf.random_uniform(shape=[10, 5], minval=-0.1, maxval= 0.1,\n",
    "                                  dtype=tf.float32), name = 'w') # Variable\n",
    "b = tf.Variable(tf.zeros(shape=[5], dtype=tf.float32), name ='b') # Variable\n",
    "h = tf.nn.sigmoid(tf.matmul(X, w) + b) # Operation to be performed\n",
    "\n",
    "# Executing operations and evaluating nodes in the graph\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    '''而在實際讀取資料前，要先在另外一個執行緒中啟動佇列執行器，才能讀取資料：'''\n",
    "    # 建立 Coordinator   \n",
    "    coord = tf.train.Coordinator()\n",
    "    # 啟動佇列執行器\n",
    "    threads = tf.train.start_queue_runners(coord = coord, sess = sess)\n",
    "    \n",
    "    # Calculate h with x and print the results foe 5 steps\n",
    "    #for step in range(5):    \n",
    "    for step in range(5):\n",
    "        X_eval, h_eval = sess.run([X,h])\n",
    "        print('========== Step %d ===========' %step)\n",
    "        print(' Evaluated data (X)')\n",
    "        print(X_eval)\n",
    "        print(' Evaluated data (h)')\n",
    "        print(h_eval)\n",
    "        print('')\n",
    "    # We also need to explicitly stop the coordinator\n",
    "    # otherwise the process will hang indefinitely\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
