{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Peter\\Anaconda36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1:\n",
      " [[0. 1. 2. 3. 4.]\n",
      " [5. 6. 7. 8. 9.]]\n",
      "a2:\n",
      " [[10. 12. 14. 16. 18.]\n",
      " [20. 22. 24. 26. 28.]]\n",
      "a3:\n",
      " [[ 6.  8. 10. 12. 14.]\n",
      " [16. 18. 20. 22. 24.]]\n",
      "a:\n",
      " [array([[0., 1., 2., 3., 4.],\n",
      "       [5., 6., 7., 8., 9.]]), array([[10., 12., 14., 16., 18.],\n",
      "       [20., 22., 24., 26., 28.]]), array([[ 6.,  8., 10., 12., 14.],\n",
      "       [16., 18., 20., 22., 24.]])]\n"
     ]
    }
   ],
   "source": [
    "a1= np.array([[0., 1., 2., 3., 4.],  [5., 6., 7., 8., 9.]])\n",
    "a2= np.array([[10.,12.,14.,16.,18.], [20.,22.,24.,26.,28.]])\n",
    "a3= np.array([[ 6., 8.,10.,12.,14.], [16.,18.,20.,22.,24.]])\n",
    "a = [a1,  a2,  a3]\n",
    "print('a1:\\n', a1)\n",
    "print('a2:\\n', a2)\n",
    "print('a3:\\n', a3)\n",
    "print('a:\\n', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1:\n",
      " [[50. 52. 54. 56. 58.]\n",
      " [60. 62. 64. 66. 68.]]\n",
      "b2:\n",
      " [[30. 32. 34. 36. 38.]\n",
      " [40. 42. 44. 46. 48.]]\n",
      "b3:\n",
      " [[12. 14. 16. 18. 20.]\n",
      " [22. 24. 26. 28. 30.]]\n",
      "b:\n",
      " [array([[50., 52., 54., 56., 58.],\n",
      "       [60., 62., 64., 66., 68.]]), array([[30., 32., 34., 36., 38.],\n",
      "       [40., 42., 44., 46., 48.]]), array([[12., 14., 16., 18., 20.],\n",
      "       [22., 24., 26., 28., 30.]])]\n"
     ]
    }
   ],
   "source": [
    "b1= np.array([[50.,52.,54.,56.,58.], [60., 62., 64., 66., 68.]])\n",
    "b2= np.array([[30.,32.,34.,36.,38.], [40., 42., 44., 46., 48.]])\n",
    "b3= np.array([[12.,14.,16.,18.,20.], [22., 24., 26., 28., 30.]])\n",
    "b = [b1,  b2,  b3]\n",
    "print('b1:\\n', b1)\n",
    "print('b2:\\n', b2)\n",
    "print('b3:\\n', b3)\n",
    "print('b:\\n', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_array_325:\n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]]\n",
      "\n",
      " [[10. 12. 14. 16. 18.]\n",
      "  [20. 22. 24. 26. 28.]]\n",
      "\n",
      " [[ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "b_array_325:\n",
      " [[[50. 52. 54. 56. 58.]\n",
      "  [60. 62. 64. 66. 68.]]\n",
      "\n",
      " [[30. 32. 34. 36. 38.]\n",
      "  [40. 42. 44. 46. 48.]]\n",
      "\n",
      " [[12. 14. 16. 18. 20.]\n",
      "  [22. 24. 26. 28. 30.]]]\n"
     ]
    }
   ],
   "source": [
    "a_array_325= np.array(a)\n",
    "b_array_325= np.array(b)\n",
    "print('a_array_325:\\n', a_array_325)\n",
    "print('b_array_325:\\n', b_array_325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_array_235:\n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [10. 12. 14. 16. 18.]\n",
      "  [ 6.  8. 10. 12. 14.]]\n",
      "\n",
      " [[ 5.  6.  7.  8.  9.]\n",
      "  [20. 22. 24. 26. 28.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "b_array_235:\n",
      " [[[50. 52. 54. 56. 58.]\n",
      "  [30. 32. 34. 36. 38.]\n",
      "  [12. 14. 16. 18. 20.]]\n",
      "\n",
      " [[60. 62. 64. 66. 68.]\n",
      "  [40. 42. 44. 46. 48.]\n",
      "  [22. 24. 26. 28. 30.]]]\n"
     ]
    }
   ],
   "source": [
    "a_array_235 = np.reshape(np.hstack(a_array_325), (2, 3, 5))\n",
    "b_array_235 = np.reshape(np.hstack(b_array_325), (2, 3, 5))\n",
    "print('a_array_235:\\n', a_array_235)\n",
    "print('b_array_235:\\n', b_array_235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a235_m_b235: (2, 3, 5) \n",
      " [[[   0.   52.  108.  168.  232.]\n",
      "  [ 300.  384.  476.  576.  684.]\n",
      "  [  72.  112.  160.  216.  280.]]\n",
      "\n",
      " [[ 300.  372.  448.  528.  612.]\n",
      "  [ 800.  924. 1056. 1196. 1344.]\n",
      "  [ 352.  432.  520.  616.  720.]]]\n"
     ]
    }
   ],
   "source": [
    "a235_m_b235 = (a_array_235 * b_array_235)\n",
    "print('a235_m_b235:', a235_m_b235.shape,'\\n', a235_m_b235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab235_avg:\n",
      " 2340.0\n"
     ]
    }
   ],
   "source": [
    "ab235_avg = tf.reduce_sum(a235_m_b235)/(2*3)\n",
    "sess = tf.Session()\n",
    "ab235_avg_v = sess.run(ab235_avg)\n",
    "print('ab235_avg:\\n', ab235_avg_v)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rev_a_325  (3, 2, 5) \n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]]\n",
      "\n",
      " [[10. 12. 14. 16. 18.]\n",
      "  [20. 22. 24. 26. 28.]]\n",
      "\n",
      " [[ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "rev_b_325  (3, 2, 5) \n",
      " [[[50. 52. 54. 56. 58.]\n",
      "  [60. 62. 64. 66. 68.]]\n",
      "\n",
      " [[30. 32. 34. 36. 38.]\n",
      "  [40. 42. 44. 46. 48.]]\n",
      "\n",
      " [[12. 14. 16. 18. 20.]\n",
      "  [22. 24. 26. 28. 30.]]]\n"
     ]
    }
   ],
   "source": [
    "rev_a_325 = np.reshape(np.hstack(a_array_235), (3, 2, 5))\n",
    "rev_b_325 = np.reshape(np.hstack(b_array_235), (3, 2, 5))\n",
    "print('rev_a_325 ',rev_a_325.shape, '\\n', rev_a_325)                       \n",
    "print('rev_b_325 ',rev_b_325.shape, '\\n', rev_b_325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_array_325  (3, 2, 5) \n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]]\n",
      "\n",
      " [[10. 12. 14. 16. 18.]\n",
      "  [20. 22. 24. 26. 28.]]\n",
      "\n",
      " [[ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "b_array_325  (3, 2, 5) \n",
      " [[[50. 52. 54. 56. 58.]\n",
      "  [60. 62. 64. 66. 68.]]\n",
      "\n",
      " [[30. 32. 34. 36. 38.]\n",
      "  [40. 42. 44. 46. 48.]]\n",
      "\n",
      " [[12. 14. 16. 18. 20.]\n",
      "  [22. 24. 26. 28. 30.]]]\n"
     ]
    }
   ],
   "source": [
    "print('a_array_325 ',a_array_325.shape, '\\n', a_array_325)\n",
    "print('b_array_325 ',b_array_325.shape, '\\n', b_array_325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a325_m_b325_rev: (3, 2, 5) \n",
      " [[[   0.   52.  108.  168.  232.]\n",
      "  [ 300.  372.  448.  528.  612.]]\n",
      "\n",
      " [[ 300.  384.  476.  576.  684.]\n",
      "  [ 800.  924. 1056. 1196. 1344.]]\n",
      "\n",
      " [[  72.  112.  160.  216.  280.]\n",
      "  [ 352.  432.  520.  616.  720.]]]\n"
     ]
    }
   ],
   "source": [
    "a325_m_b325_rev = rev_a_325 * rev_b_325\n",
    "print('a325_m_b325_rev:',a325_m_b325_rev.shape, '\\n', a325_m_b325_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a235_m_b235: (2, 3, 5) \n",
      " [[[   0.   52.  108.  168.  232.]\n",
      "  [ 300.  384.  476.  576.  684.]\n",
      "  [  72.  112.  160.  216.  280.]]\n",
      "\n",
      " [[ 300.  372.  448.  528.  612.]\n",
      "  [ 800.  924. 1056. 1196. 1344.]\n",
      "  [ 352.  432.  520.  616.  720.]]]\n"
     ]
    }
   ],
   "source": [
    "print('a235_m_b235:',a235_m_b235.shape, '\\n', a235_m_b235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab325_avg:\n",
      " 2340.0\n"
     ]
    }
   ],
   "source": [
    "ab325_avg = tf.reduce_sum(a325_m_b325_rev)/(2*3)\n",
    "sess = tf.Session()\n",
    "ab325_avg_v = sess.run(ab325_avg)\n",
    "print('ab325_avg:\\n', ab325_avg_v)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a25_list:\n",
      " [array([[0., 1., 2., 3., 4.],\n",
      "       [5., 6., 7., 8., 9.]]), array([[10., 12., 14., 16., 18.],\n",
      "       [20., 22., 24., 26., 28.]]), array([[ 6.,  8., 10., 12., 14.],\n",
      "       [16., 18., 20., 22., 24.]])]\n",
      "b25_list:\n",
      " [array([[50., 52., 54., 56., 58.],\n",
      "       [60., 62., 64., 66., 68.]]), array([[30., 32., 34., 36., 38.],\n",
      "       [40., 42., 44., 46., 48.]]), array([[12., 14., 16., 18., 20.],\n",
      "       [22., 24., 26., 28., 30.]])]\n"
     ]
    }
   ],
   "source": [
    "a25_list = []\n",
    "b25_list = []\n",
    "for ui in range(3):\n",
    "    aui = np.array(rev_a_325[ui])\n",
    "    a25_list.append(aui)\n",
    "    bui = np.array(rev_b_325[ui])\n",
    "    b25_list.append(bui)\n",
    "print('a25_list:\\n', a25_list)\n",
    "print('b25_list:\\n', b25_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a25_list:\n",
      " [array([[0., 1., 2., 3., 4.],\n",
      "       [5., 6., 7., 8., 9.]]), array([[10., 12., 14., 16., 18.],\n",
      "       [20., 22., 24., 26., 28.]]), array([[ 6.,  8., 10., 12., 14.],\n",
      "       [16., 18., 20., 22., 24.]])]\n",
      "\n",
      "a:\n",
      " [array([[0., 1., 2., 3., 4.],\n",
      "       [5., 6., 7., 8., 9.]]), array([[10., 12., 14., 16., 18.],\n",
      "       [20., 22., 24., 26., 28.]]), array([[ 6.,  8., 10., 12., 14.],\n",
      "       [16., 18., 20., 22., 24.]])]\n"
     ]
    }
   ],
   "source": [
    "print('a25_list:\\n', a25_list)\n",
    "print()\n",
    "print('a:\\n', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b25_list:\n",
      " [array([[50., 52., 54., 56., 58.],\n",
      "       [60., 62., 64., 66., 68.]]), array([[30., 32., 34., 36., 38.],\n",
      "       [40., 42., 44., 46., 48.]]), array([[12., 14., 16., 18., 20.],\n",
      "       [22., 24., 26., 28., 30.]])]\n",
      "\n",
      "b:\n",
      " [array([[50., 52., 54., 56., 58.],\n",
      "       [60., 62., 64., 66., 68.]]), array([[30., 32., 34., 36., 38.],\n",
      "       [40., 42., 44., 46., 48.]]), array([[12., 14., 16., 18., 20.],\n",
      "       [22., 24., 26., 28., 30.]])]\n"
     ]
    }
   ],
   "source": [
    "print('b25_list:\\n', b25_list)\n",
    "print()\n",
    "print('b:\\n', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_a25_list:\n",
      " [[ 0.  1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.  9.]\n",
      " [10. 12. 14. 16. 18.]\n",
      " [20. 22. 24. 26. 28.]\n",
      " [ 6.  8. 10. 12. 14.]\n",
      " [16. 18. 20. 22. 24.]]\n",
      "concat_b25_list:\n",
      " [[50. 52. 54. 56. 58.]\n",
      " [60. 62. 64. 66. 68.]\n",
      " [30. 32. 34. 36. 38.]\n",
      " [40. 42. 44. 46. 48.]\n",
      " [12. 14. 16. 18. 20.]\n",
      " [22. 24. 26. 28. 30.]]\n",
      "a25_m_b25_avg:  2340.0\n"
     ]
    }
   ],
   "source": [
    "concat_a25_list = tf.concat(a25_list, 0)\n",
    "concat_b25_list = tf.concat(b25_list, 0)\n",
    "a25_m_b25_avg =tf.reduce_sum(concat_a25_list * concat_b25_list)/(3*2) \n",
    "sess = tf. Session()\n",
    "cona25, conab25, a25mb25avg =sess.run([concat_a25_list,\\\n",
    "                               concat_b25_list,a25_m_b25_avg])\n",
    "print('concat_a25_list:\\n', cona25)\n",
    "print('concat_b25_list:\\n', conab25)\n",
    "print('a25_m_b25_avg: ', a25mb25avg)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_array_325: (3, 2, 5) \n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]]\n",
      "\n",
      " [[10. 12. 14. 16. 18.]\n",
      "  [20. 22. 24. 26. 28.]]\n",
      "\n",
      " [[ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "\n",
      "a325_hst: (2, 15) \n",
      " [[ 0.  1.  2.  3.  4. 10. 12. 14. 16. 18.  6.  8. 10. 12. 14.]\n",
      " [ 5.  6.  7.  8.  9. 20. 22. 24. 26. 28. 16. 18. 20. 22. 24.]]\n",
      "\n",
      "a235: (2, 3, 5) \n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [10. 12. 14. 16. 18.]\n",
      "  [ 6.  8. 10. 12. 14.]]\n",
      "\n",
      " [[ 5.  6.  7.  8.  9.]\n",
      "  [20. 22. 24. 26. 28.]\n",
      "  [16. 18. 20. 22. 24.]]]\n"
     ]
    }
   ],
   "source": [
    "a325_hst = np.hstack(a_array_325)\n",
    "a235 = np.reshape(a325_hst, (2, 3, 5))\n",
    "print('a_array_325:', a_array_325.shape, '\\n', a_array_325)\n",
    "print()\n",
    "print('a325_hst:', a325_hst.shape, '\\n', a325_hst)\n",
    "print()\n",
    "print('a235:', a235.shape, '\\n', a235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a235_hst: (2, 15) \n",
      " [[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [10. 12. 14. 16. 18. 20. 22. 24. 26. 28.]\n",
      " [ 6.  8. 10. 12. 14. 16. 18. 20. 22. 24.]]\n",
      "\n",
      "a325: (3, 2, 5) \n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]]\n",
      "\n",
      " [[10. 12. 14. 16. 18.]\n",
      "  [20. 22. 24. 26. 28.]]\n",
      "\n",
      " [[ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "\n",
      "a_array_325: (3, 2, 5) \n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]]\n",
      "\n",
      " [[10. 12. 14. 16. 18.]\n",
      "  [20. 22. 24. 26. 28.]]\n",
      "\n",
      " [[ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n"
     ]
    }
   ],
   "source": [
    "a235_hst = np.hstack(a235)\n",
    "a325 = np.reshape(a235_hst, (3, 2, 5))\n",
    "print('a235_hst:', a325_hst.shape, '\\n', a235_hst)\n",
    "print()\n",
    "print('a325:', a325.shape, '\\n', a325)\n",
    "print()\n",
    "print('a_array_325:', a_array_325.shape, '\\n', a_array_325)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a325 shape: (3, 2, 5)\n",
      "a325 size axis 0: 3\n",
      "a325 size axis 1: 2\n",
      "a325 size axis 2: 5\n"
     ]
    }
   ],
   "source": [
    "print('a325 shape:', a325.shape)\n",
    "print('a325 size axis 0:', np.size(a325 ,0))\n",
    "print('a325 size axis 1:', np.size(a325 ,1))\n",
    "print('a325 size axis 2:', np.size(a325 ,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_roll: 3\n",
      "batch_size: 2\n",
      "axis_1: 5\n"
     ]
    }
   ],
   "source": [
    "# a25_m_b25_avg =tf.reduce_sum(concat_a25_list * concat_b25_list)/(3*2)\n",
    "n_roll = len(a25_list)\n",
    "batch_size = np.size(a25_list[0], 0)\n",
    "axis_1 = np.size(a25_list[0], 1)\n",
    "print('n_roll:', n_roll)\n",
    "print('batch_size:', batch_size)\n",
    "print('axis_1:', axis_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a25mb25avg: 2340.0\n"
     ]
    }
   ],
   "source": [
    "a25mb25avg=tf.reduce_sum(concat_a25_list*concat_b25_list)/(n_roll*batch_size)\n",
    "with tf.Session() as sess:\n",
    "    print('a25mb25avg:', a25mb25avg.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a25_list_1:\n",
      " [array([[0., 1., 2., 3., 4.],\n",
      "       [5., 6., 7., 8., 9.]]), array([[10., 12., 14., 16., 18.],\n",
      "       [20., 22., 24., 26., 28.]]), array([[ 6.,  8., 10., 12., 14.],\n",
      "       [16., 18., 20., 22., 24.]])]\n",
      "b25_list_1:\n",
      " [array([[50., 52., 54., 56., 58.],\n",
      "       [60., 62., 64., 66., 68.]]), array([[30., 32., 34., 36., 38.],\n",
      "       [40., 42., 44., 46., 48.]]), array([[12., 14., 16., 18., 20.],\n",
      "       [22., 24., 26., 28., 30.]])]\n",
      "a25_list:\n",
      " [array([[0., 1., 2., 3., 4.],\n",
      "       [5., 6., 7., 8., 9.]]), array([[10., 12., 14., 16., 18.],\n",
      "       [20., 22., 24., 26., 28.]]), array([[ 6.,  8., 10., 12., 14.],\n",
      "       [16., 18., 20., 22., 24.]])]\n",
      "b25_list:\n",
      " [array([[50., 52., 54., 56., 58.],\n",
      "       [60., 62., 64., 66., 68.]]), array([[30., 32., 34., 36., 38.],\n",
      "       [40., 42., 44., 46., 48.]]), array([[12., 14., 16., 18., 20.],\n",
      "       [22., 24., 26., 28., 30.]])]\n"
     ]
    }
   ],
   "source": [
    "a25_list_1= [np.array(rev_a_325[ui]) for ui in range(n_roll)]\n",
    "b25_list_1= [np.array(rev_b_325[ui]) for ui in range(n_roll)]\n",
    "print('a25_list_1:\\n', a25_list_1)\n",
    "print('b25_list_1:\\n', b25_list_1)\n",
    "\n",
    "print('a25_list:\\n', a25_list)\n",
    "print('b25_list:\\n', b25_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.constant([[0., 1., 2., 3., 4.], [5., 6., 7., 8., 9.]])\n",
    "x2 = tf.constant([[10., 12., 14., 16., 18.], [20., 22., 24., 26., 28.]])\n",
    "x3 = tf.constant([[ 6.,  8., 10., 12., 14.], [16., 18., 20., 22., 24.]])                 \n",
    "y1 = tf.constant([[50., 52., 54., 56., 58.], [60., 62., 64., 66., 68.]])\n",
    "y2 = tf.constant([[30., 32., 34., 36., 38.], [40., 42., 44., 46., 48.]])\n",
    "y3 = tf.constant([[12., 14., 16., 18., 20.], [22., 24., 26., 28., 30.]])\n",
    "x = tf.stack([x1, x2, x3], axis=0)\n",
    "x_list = [x1, x2, x3]\n",
    "y = tf.stack([y1, y2, y3], axis=0)\n",
    "y_list = [y1, y2, y3]\n",
    "x_r325 = tf.reshape(x, [2, 3, 5])\n",
    "\n",
    "#x_hs = tf.concat(x, 2)\n",
    "#x_hs = tf.stack(tf.concat(x, 1), axis=1)\n",
    "x_hs = tf.reshape(x, [-1, 5])\n",
    "x_hs_235 = tf.reshape(x_hs, [2, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (3, 2, 5) x:\n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]]\n",
      "\n",
      " [[10. 12. 14. 16. 18.]\n",
      "  [20. 22. 24. 26. 28.]]\n",
      "\n",
      " [[ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "x_r325:\n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]\n",
      "  [10. 12. 14. 16. 18.]]\n",
      "\n",
      " [[20. 22. 24. 26. 28.]\n",
      "  [ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "x_hs:\n",
      " [[ 0.  1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.  9.]\n",
      " [10. 12. 14. 16. 18.]\n",
      " [20. 22. 24. 26. 28.]\n",
      " [ 6.  8. 10. 12. 14.]\n",
      " [16. 18. 20. 22. 24.]]\n",
      "x_hs_235:\n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]\n",
      "  [10. 12. 14. 16. 18.]]\n",
      "\n",
      " [[20. 22. 24. 26. 28.]\n",
      "  [ 6.  8. 10. 12. 14.]\n",
      "  [16. 18. 20. 22. 24.]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x_v, x_list_v, y_v, y_list_v, x_r325_v,x_hs_v,x_hs_235_v = sess.run(\n",
    "        [x, x_list, y, y_list, x_r325, x_hs, x_hs_235])\n",
    "    print('x shape:', x_v.shape, 'x:\\n', x_v)\n",
    "    #print('x list:\\n', x_list_v)\n",
    "    #print('y shape:', y_v.shape, 'y:\\n', y_v)\n",
    "    #print('y list:\\n', y_list_v)\n",
    "    print('x_r325:\\n', x_r325_v)\n",
    "    print('x_hs:\\n', x_hs_v)\n",
    "    print('x_hs_235:\\n', x_hs_235_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_us1_list = tf.unstack(x, axis=1)\n",
    "x_us1_array = tf.stack(x_us1, axis=0)\n",
    "x_us1_soft_list = [tf.nn.softmax(x_us1_list[ui]) for ui in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_us1_list type: <class 'list'> x_us1_list[0] type: (3, 5) x_us1:\n",
      " [array([[ 0.,  1.,  2.,  3.,  4.],\n",
      "       [10., 12., 14., 16., 18.],\n",
      "       [ 6.,  8., 10., 12., 14.]], dtype=float32), array([[ 5.,  6.,  7.,  8.,  9.],\n",
      "       [20., 22., 24., 26., 28.],\n",
      "       [16., 18., 20., 22., 24.]], dtype=float32)]\n",
      "x_us1_array type: <class 'numpy.ndarray'> x_us1s shape: (2, 3, 5) \n",
      " [[[ 0.  1.  2.  3.  4.]\n",
      "  [10. 12. 14. 16. 18.]\n",
      "  [ 6.  8. 10. 12. 14.]]\n",
      "\n",
      " [[ 5.  6.  7.  8.  9.]\n",
      "  [20. 22. 24. 26. 28.]\n",
      "  [16. 18. 20. 22. 24.]]]\n",
      "x_us1_soft_list type: <class 'list'> x_us1_soft_list[0] shape: (3, 5) \n",
      " [array([[1.1656231e-02, 3.1684920e-02, 8.6128540e-02, 2.3412165e-01,\n",
      "        6.3640863e-01],\n",
      "       [2.9007587e-04, 2.1433870e-03, 1.5837606e-02, 1.1702495e-01,\n",
      "        8.6470395e-01],\n",
      "       [2.9007587e-04, 2.1433870e-03, 1.5837606e-02, 1.1702495e-01,\n",
      "        8.6470395e-01]], dtype=float32), array([[1.1656231e-02, 3.1684920e-02, 8.6128540e-02, 2.3412165e-01,\n",
      "        6.3640863e-01],\n",
      "       [2.9007587e-04, 2.1433870e-03, 1.5837606e-02, 1.1702495e-01,\n",
      "        8.6470395e-01],\n",
      "       [2.9007587e-04, 2.1433870e-03, 1.5837606e-02, 1.1702495e-01,\n",
      "        8.6470395e-01]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x_us1_list_v, x_us1_array_v, x_us1_soft_list_v = sess.run(\n",
    "        [x_us1_list, x_us1_array, x_us1_soft_list])\n",
    "        \n",
    "    #print('x_us0:\\n',x_us0_v)\n",
    "    print('x_us1_list type:',type(x_us1_list_v),\n",
    "          'x_us1_list[0] type:',x_us1_list_v[0].shape,'x_us1:\\n',\n",
    "          x_us1_list_v)\n",
    "    print('x_us1_array type:',type(x_us1_array_v),\n",
    "          'x_us1s shape:', x_us1_array_v.shape,'\\n',x_us1_array_v)\n",
    "    print('x_us1_soft_list type:',type(x_us1_soft_list_v),\n",
    "          'x_us1_soft_list[0] shape:', x_us1_soft_list_v[0].shape,'\\n',\n",
    "          x_us1_soft_list_v)\n",
    "    #print('x_us2:\\n',x_us2_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1= np.array([[0., 1., 2., 3., 4.],  [5., 6., 7., 8., 9.]])\n",
    "text_digt =[5, 7, 4, 8, 0]\n",
    "text_digt[np.random.randint(0,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "#[np.random.randint(0, 100)]\n",
    "predPhase_word = np.zeros((1, 1, 10),dtype=np.float32) \n",
    "predPhase_word[0, 0, text_digt[np.random.randint(0, 5)]] = 1.0\n",
    "print(predPhase_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 10, 100)\n",
      "rnn_cell.state_size: 128\n",
      "initial_state.shape: (32, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/basic_rnn_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-15832c13780e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# 创建dynamic_rnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\u001b[0m\n\u001b[0;32m   3207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3209\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3211\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2939\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2941\u001b[1;33m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2943\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2876\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m   2877\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2879\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   3177\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   3178\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 3179\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    784\u001b[0m           skip_conditionals=True)\n\u001b[0;32m    785\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[1;31m# Pack state if using state tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;31m# method.  See the class docstring for more details.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\n\u001b[1;32m--> 339\u001b[1;33m                                      *args, **kwargs)\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, inputs_shape)\u001b[0m\n\u001b[0;32m    387\u001b[0m     self._kernel = self.add_variable(\n\u001b[0;32m    388\u001b[0m         \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         shape=[input_depth + self._num_units, self._num_units])\n\u001b[0m\u001b[0;32m    390\u001b[0m     self._bias = self.add_variable(\n\u001b[0;32m    391\u001b[0m         \u001b[0m_BIAS_VARIABLE_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_variable\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    458\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0madd_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;34m\"\"\"Alias for `add_weight`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m   def add_weight(self, name, shape,\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, partitioner)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             getter=vs.get_variable)\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, getter)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         use_resource=use_resource)\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    495\u001b[0m     new_variable = getter(\n\u001b[0;32m    496\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1326\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1328\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1329\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1330\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1088\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    433\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    402\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    741\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 743\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    744\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable rnn/basic_rnn_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\Peter\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
